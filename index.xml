<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Wizard&#39;s Cabin</title>
    <link>https://shadw3002.github.io/</link>
    <description>Recent content on Wizard&#39;s Cabin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><atom:link href="https://shadw3002.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bigtable</title>
      <link>https://shadw3002.github.io/posts/bigtable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/bigtable/</guid>
      <description>References  《BigTable: A System for Distributed Structured Storage》 by Jeff Dean 《Bigtable: A Distributed Storage System for Structured Data》 by Fay Chang , Jeffrey Dean , Sanjay Ghemawat , Wilson C. Hsieh , Deborah A. Wallach , Mike Burrows , Tushar Ch,ra , ,rew Fikes , Robert E. Gruber Bigtable 论文中文翻译 https://www.zhihu.com/question/19551534/answer/116874719 https://www.slideshare.net/kyhpudding/dreaming-infrastructure 57 - Structure and Interpretation of Computer Programs, Second Edition  引导 如何学习这种架构？围绕哪些问题进行学习？
 先快速看一下 QuickStart 有个直观认识。 阅读、查资料猜它怎么实现。 思考用了什么技术，对后面的技术产生什么影响。  Intro 2006 年，Google 在 OSDI 发布了 Bigtable 论文，其设计和实现开始于 2004 年，在 2006 年已经有 100 个 cluster 部署，支撑众多业务，其中最大的 cluster 在数千台机器上管理了 200TB 的数据。</description>
    </item>
    
    <item>
      <title>continuation</title>
      <link>https://shadw3002.github.io/posts/continuation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/continuation/</guid>
      <description>References  《The Scheme Programming Language, 4th Edition》 by 未知 http://blog.sina.com.cn/s/blog_4dff871201018wtz.html  TODO
 https://www.zhihu.com/question/61222322/answer/564847803 https://zhuanlan.zhihu.com/p/49117340 https://www.sczyh30.com/posts/Functional-Programming/call-with-current-continuation/ https://www.zhihu.com/question/21954238/answer/1829986581  Intro Scheme 是第一个提供 conitnuation 的语言。
对于 Scheme 在整个表达式求值的过程中，任何一个子表达式都对应一个 contination ，其表示该子表达式求值完成后继续完成整个表达式的求值的过程。
Scheme 提供过程 call/cc 以捕获任何表达式对应的 continuation ，使用方法为 (call/cc p) ，其中 p 为一个过程，接收 call/cc 捕获的 current continuation （简称 cc） 作为入参，调用 call/cc 时，其捕获 cc 并应用在 p 上，将应用 cc 到 p 上求得的值作为其自身应用求得的值（前提是 cc 没被应用）。捕获到的 cc 是一个过程，可以应用一个参数 v 到 cc 上，若如此则程序的 current continuation 会替换为 cc ，并将 v 作为捕获 cc 时对应的子表达式的返回值。</description>
    </item>
    
    <item>
      <title>GFS</title>
      <link>https://shadw3002.github.io/posts/gfs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/gfs/</guid>
      <description>References  MIT 6.824 《The Google File System》 by 未知 https://zhuanlan.zhihu.com/p/354450124 http://duanple.com/?p=202  Why  为什么单 master 能很好工作 弱一致性为何能容忍 异地副本的难点在于 为什么是 master 主动 ping chunk server 如何将 GFS 变得更一致：https://zhuanlan.zhihu.com/p/187542327  Intro GFS 发表于 2003 年的 SOSP。
GFS 将文件分为多个 chunk 存储，一个 chunk 冗余三份并存放于 chunkserver，client 直接与 chunkserver 通信进行读写，而 master 只管理元数据。
GFS 被设计于承担面向顺序读写大文件的工作负载，且适用于写完就只读的情况。
GFS 只能在一个数据中心运行，没有将副本保存到异地 TODO
GFS 的意义在于展示现实大规模分布式系统的设计，并反映了工业界与学术界 concern 的点的差异：
 GFS 论文发表在 2003 年的 SOSP 会议上，这是一个有关系统的顶级学术会议。通常来说，这种会议的论文标准是需要有大量的创新研究，但是 GFS 的论文不属于这一类标准。论文中的一些思想在当时都不是特别新颖，比如分布式，分片，容错这些在当时已经知道如何实现了。
 这篇论文的特点是，它描述了一个真正运行在成百上千台计算机上的系统，这个规模远远超过了学术界建立的系统。并且由于 GFS 被用于工业界，它反映了现实世界的经验，例如对于一个系统来说，怎样才能正常工作，怎样才能节省成本，这些内容也极其有价值。 提出在当时非常异类的观点： 存储系统具有弱一致性也是可以的。当时，学术界的观念认为，存储系统就应该有良好的行为，如果构建了一个会返回错误数据的系统，就像前面（详见3.</description>
    </item>
    
    <item>
      <title>LevelDB Compaction</title>
      <link>https://shadw3002.github.io/posts/compaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/compaction/</guid>
      <description>简介 LevelDB 中的 Compaction 分为两种，Minor Compaction 和 Major Compaction 。
Minor Compaction  Minor Compaction 将内存中的 MemTable dump 到外存，产生一个 SSTable 文件。
此外，Minor Compaction 优先级高于 Major Compaction 。
Major Compaction  Major Combination 用于 level 间的 merge ，一次合并将层 i 的一个 SSTable 合并到层 i+1 。
 对于 level &amp;gt; 0 的 SSTable，选择其中一个 SSTable 与 下一层 SSTable 做合并 对于 level-0 的 SSTable，会将 SSTable 合并成多个不重叠的 1 层 SSTable 。  触发时机  当 0 层 SSTable 数超过阈值（默认为 4） 由于 Compaction 的其中一个目的是为了提高读取的效率，因此 LevelDB 不允许 0 层存在过多的文件数，一旦超过了上限值，即可进行 Major Compaction。 当 level-i 层 SSTable 的总大小超过阈值（10^i MB） 对于level i（i &amp;gt;= 1）的情况来说，一个读取最多只会访问一个 SSTable 文件，因此，SSTable 数对于读取效率的影响不会太大。针对于这部分数据发生 Compaction 的条件，从提升读取效率转变成了降低 Compaction 的 IO 开销。此外，这也有助于减低 Compaction 的开销。  当某个 SSTable 无效读取的次数过多 :</description>
    </item>
    
    <item>
      <title>LevelDB LogFile</title>
      <link>https://shadw3002.github.io/posts/logfile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/logfile/</guid>
      <description>References Intro LevelDB 是 WAL 的，写入必须先写入 Log 才算成功，将 LevelDB 视为状态机，Log 文件就代表 LevelDB 的状态转移，LogFile 可以认为代表了当前 LevelDB 的状态，而 LSM-Tree 可以认为是 LogFile 状态的存储和索引方式，故障恢复时可以重放 Logfile 从 Snapshot 点重新构建 LSM-Tree 的 Memtable（SSTable 是持久化的，不需要重新构建）。
LogFile 的主要作用是：顺序化写入、故障恢复。
db/log_writer.h
Status Writer::AddRecord(const Slice&amp;amp; slice); bool Reader::ReadRecord(Slice* record, std::string* scratch); // scratch as temporarily buffer 结构  db/log_format.h
enum RecordType { // Zero is reserved for preallocated files  kZeroType = 0, kFullType = 1, // For fragments  kFirstType = 2, kMiddleType = 3, kLastType = 4 }; static const int kMaxRecordType = kLastType; static const int kBlockSize = 32768; // Header is checksum (4 bytes), length (2 bytes), type (1 byte).</description>
    </item>
    
    <item>
      <title>LevelDB MemTable</title>
      <link>https://shadw3002.github.io/posts/memtable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/memtable/</guid>
      <description>简介 LevelDB 的 MemTable 使用跳表实现，MemTable 是内存中的结构，支持插入和查找操作，支持一写多读。当 Memtable 中的数据占用内存大小达到 write_buffer_size 则将被转换为 Immutable Memtable ，同时创建一个新的 Memtable ，Immutable Memtable 会在后台被 dump 成 SSTable 。
这里存在的问题是，Immutable MemTable 没有及时 dump 的话，会阻塞新的 Memtable 的创建，阻塞写请求。
用户接口与数据模型 class MemTable { // Returns an estimate of the number of bytes of data in use by this  // data structure. It is safe to call when MemTable is being modified.  size_t ApproximateMemoryUsage(); // Return an iterator that yields the contents of the memtable.</description>
    </item>
    
    <item>
      <title>LevelDB SkipList</title>
      <link>https://shadw3002.github.io/posts/skiplist/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/skiplist/</guid>
      <description>简介 LevelDB SkipList 除非被销毁，否则跳表节点不删除，且节点的 key 和 value 一经插入即不可修改，SkipList 支持无锁的一写多读场景。
用户接口 template &amp;lt;typename Key, class Comparator&amp;gt; class SkipList { public: // Create a new SkipList object that will use &amp;#34;cmp&amp;#34; for comparing keys,  // and will allocate memory using &amp;#34;*arena&amp;#34;. Objects allocated in the arena  // must remain allocated for the lifetime of the skiplist object.  explicit SkipList(Comparator cmp, Arena* arena); // Insert key into the list.  // REQUIRES: nothing that compares equal to key is currently in the list.</description>
    </item>
    
    <item>
      <title>LevelDB SSTable</title>
      <link>https://shadw3002.github.io/posts/sstable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/sstable/</guid>
      <description>简介 Leveldb 内存中 MemTable 的数据达到阈值，会将数据 dump 到磁盘中形成 SSTable 文件。不同 SSTable 的 Key Range 是存在交集的，在读操作时，需要对所有的 SSTable文件进行遍历，影响读速度，后台需要定期合并部分 SSTable 文件，该过程称为 Compaction。随着 Compaction 的进行，SSTable 文件在逻辑上被分成若干层，由内存数据直接 dump 出来的文件称为 level 0 层文件，后期整合而成的文件为 level i 层文件，这也是 LevelDB 这个名字的由来。
文件格式 Block SSTable文件按 4K 分 Block ，每个 Block 中，除了存储数据以外，还会存储两个额外的辅助字段：压缩类型和 CRC 校验码，LevelDB 默认采用 Snappy 算法 进行压缩。
   Data Compact Type CRC     Data Compact Type CRC   Data Compact Type CRC   Data Compact Type CRC    Block 有以下种类，其中前四种 Block 具有先前提到的结构：</description>
    </item>
    
    <item>
      <title>LSM-Tree</title>
      <link>https://shadw3002.github.io/posts/lsm-tree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/lsm-tree/</guid>
      <description>简介 LSM-Tree 的设计可以认为受两个观点的启发：
 The Five Minute Rule ：对于硬盘中的结构，当存在相对热的硬盘页时， 引入内存结构来分摊硬盘 I/O 开销。 Log-Structured ：对于写场景较多的硬盘中的结构， 使用日志结构，转化随机写为顺序批量写来降低写入硬盘 I/O 开销。  LSM-Tree 是针对 写多读少的场景提出的，在这个场景下，经典的 B-tree 的写放大会导致额外的 I/O 开销：
 Unfortunately, standard disk-based index structures such as the B-tree will effectively double the I/O cost of the transaction to maintain an index such as this in real time, increasing the total system cost up to fifty percent.
 LSM-Tree 是一种硬盘上的数据结构，能在多写且建索引的场景下降低 I/O 开销：
 The Log-Structured Merge-tree (LSM-tree) is a disk-based data structure designed to provide low-cost indexing for a file experiencing a high rate of record inserts (and deletes) over an extended period.</description>
    </item>
    
    <item>
      <title>MapReduce</title>
      <link>https://shadw3002.github.io/posts/mapreduce/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/mapreduce/</guid>
      <description>References  MIT 6.824 《MapReduce: Simplified Data Processing on Large Clusters》 by 未知 https://zhuanlan.zhihu.com/p/46454413 http://duanple.com/?p=199  Intro MapReduce 是一个分布式计算的抽象。
抽象 MapReduce 的思想来自函数式编程。
对于这样的分布式计算过程（输入一组 KV 对，输出一组 KV 对），抽象为多个 Map 和 Reduce 过程，整个过程称为 Job ，每次 Map 或 Reduce 过程称为 Task, Map 和 Reduce 可以级联组合。用户实现整个计算过程，就要实现多个 Job 并组合成 Task 。
Map 和 Reduce 的形式化定义：
$$
\begin{array}{lll} \operatorname{map} &amp;amp; (k 1, v 1) &amp;amp; \rightarrow \operatorname{list}(k 2, v 2) \\
\text { reduce } &amp;amp; (k 2, \operatorname{list}(v 2)) &amp;amp; \rightarrow \operatorname{list}\left(v_{2}\right) \end{array}</description>
    </item>
    
  </channel>
</rss>
