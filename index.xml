<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Wizard&#39;s Cabin</title>
    <link>https://shadw3002.github.io/</link>
    <description>Recent content on Wizard&#39;s Cabin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Mon, 29 Nov 2021 00:00:00 +0800</lastBuildDate><atom:link href="https://shadw3002.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>C&#43;&#43; Value Category</title>
      <link>https://shadw3002.github.io/posts/cpp-vg/</link>
      <pubDate>Mon, 29 Nov 2021 00:00:00 +0800</pubDate>
      
      <guid>https://shadw3002.github.io/posts/cpp-vg/</guid>
      <description>简介 值类别是 C++ 表达式具有的属性之一（还有其类型）。
C++ 最开始只有 左值与右值 的说法，且其含义随着时间变化和模糊，后来，为了支持 移动语义 ，C++11 引入了 右值引用 ，C++ 标准委员会重新设计了值类别，新的类别系统围绕 identity 和 movable 这个两个概念定义了核心值类别类型 lvalue 、xvalue 、prvalue ，以及复合值类别类型 glvalue 、rvalue ，再后来 C++17 为了消除 [Copy Elision 导致构造函数调用的不明确，围绕 glvalue 提供被初始化对象地址、prvalue 提供 initializer 重新明确了前面五种值。
  glvalue（generalized lvalue） an expression whose evaluation determines the identity of an object, bit-field, or function. rvalue a prvalue or an xvalue. lvalue a glvalue that is not an xvalue. xvalue（expiring value） a glvalue that denotes an object or bit-field whose resources can be reused （usually because it is near the end of its lifetime）.</description>
    </item>
    
    <item>
      <title>BigTable</title>
      <link>https://shadw3002.github.io/posts/bigtable/</link>
      <pubDate>Wed, 17 Nov 2021 00:00:00 +0800</pubDate>
      
      <guid>https://shadw3002.github.io/posts/bigtable/</guid>
      <description>引导 如何学习这种架构？围绕哪些问题进行学习？
 先快速看一下 QuickStart 有个直观认识。 阅读、查资料猜它怎么实现。 思考用了什么技术，对后面的技术产生什么影响。  简介 2006 年，Google 在 OSDI 发布了 Bigtable 论文，其设计和实现开始于 2004 年，在 2006 年已经有 100 个 cluster 部署，支撑众多业务，其中最大的 cluster 在数千台机器上管理了 200TB 的数据。
Bigtable 是 Google 的三驾马车之一，在 Google 的基础架构生态中，Bigtable 位于 GFS 之上，为上层应用提供了一个中间层存储，致力于提供一个解决方案来满足 Google 内部差异较大的不同业务场景需求，可以容纳 PB 级数据、可以满足线上实时查询的低延迟、大量（半）结构化数据，并支持随机写入、高读写速率、高效的 scan、多版本等特性。
如果要下个定义，那么 Bigtable 是一个分布式的、排序的、支持行内事务的、半结构化的、支持多版本、支持在线和离线场景的列簇数据库 （不完全是）。
QuickStart https://www.w3cschool.cn/hbase_doc/hbase_doc-m3y62k51.html
数据模型 Bigtable 提供给用户的数据模型是排序大表 + 列簇。
cluster 是多个进程组成的一个 Bigtable 实例，一个 cluster 可以容纳多个 table ，table 是一个稀疏的、分布式的、一致的、多维的一个 map 。用 row 、column、timestamp 索引 map 得到 cell ，其中 row 、 column 和 cell 都是 bytes ，并且 column key 的格式为 family:qualifier 。</description>
    </item>
    
    <item>
      <title>The Google File System</title>
      <link>https://shadw3002.github.io/posts/gfs/</link>
      <pubDate>Tue, 05 Oct 2021 00:00:00 +0800</pubDate>
      
      <guid>https://shadw3002.github.io/posts/gfs/</guid>
      <description>简介 GFS 发表于 2003 年的 SOSP ，Google 基于 GFS 用大量相对廉价的机器承载依赖大量数据的应用。GFS 将文件分为多个 chunk 存储，一个 chunk 冗余三份并存放于 chunkserver，client 直接与 chunkserver 通信进行读写，而 master 只管理元数据。GFS 被设计于承担面向顺序读写大文件的工作负载，且适用于写完就只读的情况。
个人读完论文后的几个感想：
 简单粗暴 实在是太简单粗暴了。 租约的思想 收敛分布式文件读写的全局协商到单机。 Master 绝大多数时候没有 Master 的单点通信问题。 特定负载特化 被特意设计为 append-only 和写后只读的工作负载。 弱一致性 这是双刃剑，这使得 GFS 可以简单粗暴地应对一些情况，但是需要业务充分理解松弛一致性模型后自己在上层做容错。  有人说 GFS 的意义在于展示现实大规模分布式系统的设计，并反映了工业界与学术界 concern 点的差异：
 GFS 论文发表在 2003 年的 SOSP 会议上，这是一个有关系统的顶级学术会议。通常来说，这种会议的论文标准是需要有大量的创新研究，但是 GFS 的论文不属于这一类标准。论文中的一些思想在当时都不是特别新颖，比如分布式，分片，容错这些在当时已经知道如何实现了。
 这篇论文的特点是，它描述了一个真正运行在成百上千台计算机上的系统 ，这个规模远远超过了学术界建立的系统。并且由于 GFS 被用于工业界，它反映了现实世界的经验，例如对于一个系统来说，怎样才能正常工作，怎样才能节省成本，这些内容也极其有价值。 提出在当时非常异类的观点： 存储系统具有弱一致性也是可以的 。当时，学术界的观念认为，存储系统就应该有良好的行为，如果构建了一个会返回错误数据的系统，就会像多副本系统一样，那还有什么意义？为什么不直接构建一个能返回正确数据的系统？ GFS 并不保证返回正确的数据，借助于这一点，GFS 的目标是提供更好的性能 。 在一些学术论文中，你或许可以看到一些容错的，多副本，自动修复的多个 Master 节点共同分担工作，但是 GFS 却宣称使用单个 Master 节点并能够很好的工作 。   用户接口 GFS 提供了类似 POSIX 的接口，其中 create、delete、open、close 和 POSIX 类似，而 read、write、record append 有所不同。</description>
    </item>
    
    <item>
      <title>MapReduce</title>
      <link>https://shadw3002.github.io/posts/mapreduce/</link>
      <pubDate>Sun, 03 Oct 2021 00:00:00 +0800</pubDate>
      
      <guid>https://shadw3002.github.io/posts/mapreduce/</guid>
      <description>简介 MapReduce 是一个分布式计算的抽象。
抽象 MapReduce 的思想来自函数式编程。
对于这样的分布式计算过程（输入一组 KV 对，输出一组 KV 对），抽象为多个 Map 和 Reduce 过程，整个过程称为 Job ，每次 Map 或 Reduce 过程称为 Task, Map 和 Reduce 可以级联组合。用户实现整个计算过程，就要实现多个 Job 并组合成 Task 。
Map 和 Reduce 的形式化定义：
$\begin{equation}\begin{array}{lll}\operatorname{map} &amp;amp; (k 1, v 1) &amp;amp; \rightarrow \operatorname{list}(k 2, v 2) \\\text { reduce } &amp;amp; (k 2, \operatorname{list}(v 2)) &amp;amp; \rightarrow \operatorname{list}\left(v_{2}\right)\end{array}\end{equation}$
 Map: (k1,v1) -&amp;gt; list(k2,v2)
Reduce: (k2,list(v2)) -&amp;gt; list(v2)
  Map 输入一个 KV 对，输出一组 KV 对作为中间结果，框架会将相同 Key 的 Value 组合起来一起传给 Reduce Reduce 输入一个 Key 和一组 Value ，输出一组可能更少的 Value  例子  map(String key, String value): / key: document name / value: document contents for each word w in value: EmitIntermediate(w, &amp;ldquo;1&amp;rdquo;);</description>
    </item>
    
    <item>
      <title>Log-Structured Merge-Tree</title>
      <link>https://shadw3002.github.io/posts/lsm-tree/</link>
      <pubDate>Thu, 16 Sep 2021 00:00:00 +0800</pubDate>
      
      <guid>https://shadw3002.github.io/posts/lsm-tree/</guid>
      <description>简介 LSM-Tree 的设计可以认为受两个观点的启发：
 The Five Minute Rule ：对于硬盘中的结构，当存在相对热的硬盘页时， 引入内存结构来分摊硬盘 I/O 开销 。 Log-Structured ：对于写场景较多的硬盘中的结构， 使用日志结构，转化随机写为顺序批量写来降低写入硬盘 I/O 开销 。  LSM-Tree 是针对 写多读少 的场景提出的，在这个场景下，经典的 B-tree 的写放大会导致额外的 I/O 开销：
 Unfortunately, standard disk-based index structures such as the B-tree will effectively double the I/O cost of the transaction to maintain an index such as this in real time, increasing the total system cost up to fifty percent.
 LSM-Tree 是一种硬盘上的数据结构，能在多写且建索引的场景下降低 I/O 开销：</description>
    </item>
    
    <item>
      <title>Bloom Filter</title>
      <link>https://shadw3002.github.io/posts/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</link>
      <pubDate>Sun, 12 Sep 2021 00:00:00 +0800</pubDate>
      
      <guid>https://shadw3002.github.io/posts/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</guid>
      <description>简介 Bloom Filter 由 Burton Howard Bloom 在 1970 年提出，用少量空间换取 判断元素是否在集合内 的时间开销。布隆过滤器在时间空间、保密、可伸缩性上都有很好的表现。
 当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。
 分析 结论 为了获得最优的准确率，当 \(k = ln2 \cdot (m/n)\) 时，布隆过滤器获得最优的准确性。
\(n\) 一般不变，而由分析如果给定 \(k\) ，要求此时错误率最小的话 \(m\) 和 \(k\) 是一一对应，也就是说，可以认为需要权衡如何用最少的 \(m\) 或 \(k\) ，满足 \(n\) 下的错误率上界 \(\epsilon\) 。
参数  哈希函数的个数 \(k\) 布隆过滤器位数组的容量 \(m\) 布隆过滤器插入的数据数量 \(n\)  错误率 对于一次 hash ，一个 bit 被设为 \(0\) 的概率为：
\begin{equation} 1 - \frac 1 m \end{equation}
当我们讨论错误率时，我们分析最大错误率的情况，即是已经写入 \(n-1\) 个独立的值的时候，计算时以写入 \(n\) 个值做近似，则对于一个 bit ，如果我们新写入一个值前，它为 \(1\) 的概率为：</description>
    </item>
    
    <item>
      <title>Batch Buffer</title>
      <link>https://shadw3002.github.io/posts/batch-buffer/</link>
      <pubDate>Mon, 02 Aug 2021 00:00:00 +0800</pubDate>
      
      <guid>https://shadw3002.github.io/posts/batch-buffer/</guid>
      <description>Reference Intro Push 单个元素，批量 Pop 多个元素的 Buffer 。
Implement package datastructure import ( &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; &amp;#34;log&amp;#34; ) const ( TTL = 1 * time.Second BatchSize = 128 BufferInitSize = 128 TokenSize = 32 QueueSize = 1024 PushTimeout = time.Microsecond * 500 ) type Item = *int // Inspired by Jaeger type BatchBuffer struct { buffer []Item queue chan Item close chan *sync.WaitGroup tokens chan struct{} workers *sync.WaitGroup popper func([]Item) error hook func([]Item) } func New(popper func([]Item) error, hook func([]Item)) *BatchBuffer { return &amp;amp;BatchBuffer{ buffer: make([]Item, 0, BufferInitSize), queue: make(chan Item, QueueSize), close: make(chan *sync.</description>
    </item>
    
    <item>
      <title>continuation</title>
      <link>https://shadw3002.github.io/posts/continuation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/continuation/</guid>
      <description>References  《The Scheme Programming Language, 4th Edition》 by 未知 http://blog.sina.com.cn/s/blog_4dff871201018wtz.html  TODO
 https://www.zhihu.com/question/61222322/answer/564847803 https://zhuanlan.zhihu.com/p/49117340 https://www.sczyh30.com/posts/Functional-Programming/call-with-current-continuation/ https://www.zhihu.com/question/21954238/answer/1829986581  Intro Scheme 是第一个提供 conitnuation 的语言。
对于 Scheme 在整个表达式求值的过程中，任何一个子表达式都对应一个 contination ，其表示该子表达式求值完成后继续完成整个表达式的求值的过程。
Scheme 提供过程 call/cc 以捕获任何表达式对应的 continuation ，使用方法为 (call/cc p) ，其中 p 为一个过程，接收 call/cc 捕获的 current continuation （简称 cc） 作为入参，调用 call/cc 时，其捕获 cc 并应用在 p 上，将应用 cc 到 p 上求得的值作为其自身应用求得的值（前提是 cc 没被应用）。捕获到的 cc 是一个过程，可以应用一个参数 v 到 cc 上，若如此则程序的 current continuation 会替换为 cc ，并将 v 作为捕获 cc 时对应的子表达式的返回值。</description>
    </item>
    
    <item>
      <title>LevelDB Compaction</title>
      <link>https://shadw3002.github.io/posts/compaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/compaction/</guid>
      <description>简介 LevelDB 中的 Compaction 分为两种，Minor Compaction 和 Major Compaction 。
Minor Compaction  Minor Compaction 将内存中的 MemTable dump 到外存，产生一个 SSTable 文件。
此外，Minor Compaction 优先级高于 Major Compaction 。
Major Compaction  Major Combination 用于 level 间的 merge ，一次合并将层 i 的一个 SSTable 合并到层 i+1 。
 对于 level &amp;gt; 0 的 SSTable，选择其中一个 SSTable 与 下一层 SSTable 做合并 对于 level-0 的 SSTable，会将 SSTable 合并成多个不重叠的 1 层 SSTable 。  触发时机  当 0 层 SSTable 数超过阈值（默认为 4） 由于 Compaction 的其中一个目的是为了提高读取的效率，因此 LevelDB 不允许 0 层存在过多的文件数，一旦超过了上限值，即可进行 Major Compaction。 当 level-i 层 SSTable 的总大小超过阈值（10^i MB） 对于level i（i &amp;gt;= 1）的情况来说，一个读取最多只会访问一个 SSTable 文件，因此，SSTable 数对于读取效率的影响不会太大。针对于这部分数据发生 Compaction 的条件，从提升读取效率转变成了降低 Compaction 的 IO 开销。此外，这也有助于减低 Compaction 的开销。 当某个 SSTable 无效读取的次数过多 :  Compaction 与版本 需要注意到，每次 Compaction 后，LevelDB 的持久化数据的 Snapshot （亦即 SSTable + WAL） 的版本就发生变化了。</description>
    </item>
    
    <item>
      <title>LevelDB LogFile</title>
      <link>https://shadw3002.github.io/posts/logfile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shadw3002.github.io/posts/logfile/</guid>
      <description>References Intro LevelDB 是 WAL 的，写入必须先写入 Log 才算成功，将 LevelDB 视为状态机，Log 文件就代表 LevelDB 的状态转移，LogFile 可以认为代表了当前 LevelDB 的状态，而 LSM-Tree 可以认为是 LogFile 状态的存储和索引方式，故障恢复时可以重放 Logfile 从 Snapshot 点重新构建 LSM-Tree 的 Memtable（SSTable 是持久化的，不需要重新构建）。
LogFile 的主要作用是：顺序化写入、故障恢复。
db/log_writer.h
Status Writer::AddRecord(const Slice&amp;amp; slice); bool Reader::ReadRecord(Slice* record, std::string* scratch); // scratch as temporarily buffer  结构  db/log_format.h
enum RecordType { // Zero is reserved for preallocated files  kZeroType = 0, kFullType = 1, // For fragments  kFirstType = 2, kMiddleType = 3, kLastType = 4 }; static const int kMaxRecordType = kLastType; static const int kBlockSize = 32768; // Header is checksum (4 bytes), length (2 bytes), type (1 byte).</description>
    </item>
    
  </channel>
</rss>
